{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model on clustered data\n",
    "\n",
    "Now the same models that were trained on the overall data will be trained on each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon_data = pd.read_csv(\n",
    "    r\"data\\marathon_runners.csv\", header=0).drop(columns='Unnamed: 0')\n",
    "marathon_data = marathon_data.drop_duplicates()\n",
    "marathon_data = marathon_data[marathon_data[\"week_1_total_distance\"] > 0]\n",
    "marathon_data = marathon_data[marathon_data[\"duration\"] < 480].reset_index()\n",
    "\n",
    "for column in marathon_data.columns:\n",
    "    if \"_pace\" in column:\n",
    "        marathon_data[column] = (\n",
    "            marathon_data[column] - marathon_data[\"pace\"]) / (marathon_data[\"pace\"])\n",
    "\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "X = marathon_data.loc[:, ['week_5_total_distance', 'week_6_total_distance',\n",
    "                          'week_9_total_distance', 'week_10_total_distance',\n",
    "                          'week_11_total_distance', 'week_13_total_distance',\n",
    "                          'week_14_total_distance', 'week_15_total_distance',\n",
    "                          'week_1_average_distance', 'week_7_average_distance',\n",
    "                          'week_10_average_distance', 'week_11_average_distance',\n",
    "                          'week_12_average_distance', 'week_13_average_distance',\n",
    "                          'week_14_average_distance', 'week_16_average_distance',\n",
    "                          'week_1_shortest_distance', 'week_2_longest_time',\n",
    "                          'week_3_longest_time', 'week_6_longest_time', 'week_7_longest_time',\n",
    "                          'week_9_longest_time', 'week_10_longest_time', 'week_11_longest_time',\n",
    "                          'week_12_longest_time', 'week_13_longest_time', 'week_14_longest_time',\n",
    "                          'week_15_longest_time', 'week_1_average_duration',\n",
    "                          'week_2_average_duration', 'week_3_average_duration',\n",
    "                          'week_4_average_duration', 'week_5_average_duration',\n",
    "                          'week_8_average_duration', 'week_9_average_duration',\n",
    "                          'week_11_average_duration', 'week_13_average_duration',\n",
    "                          'week_14_average_duration', 'week_15_average_duration',\n",
    "                          'week_16_average_duration', 'week_1_fastest_pace',\n",
    "                          'week_2_fastest_pace', 'week_3_fastest_pace', 'week_4_fastest_pace',\n",
    "                          'week_5_fastest_pace', 'week_6_fastest_pace', 'week_8_fastest_pace',\n",
    "                          'week_10_fastest_pace', 'week_11_fastest_pace', 'week_12_fastest_pace',\n",
    "                          'week_13_fastest_pace', 'week_14_fastest_pace', 'week_15_fastest_pace',\n",
    "                          'week_16_fastest_pace']]\n",
    "y = marathon_data.loc[:, \"duration\"]\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.array(marathon_data.loc[:, \"duration\"].astype(\"int32\")).reshape(-1,1)\n",
    "y = np.array(scaler.fit_transform(y)).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_score(test_value, predict_value):\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(test_value, predict_value)}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(test_value, predict_value))}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(test_value, predict_value)}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mean_absolute_percentage_error(test_value, predict_value)*100}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples in label 0 = 822\n",
      "Number of test samples in label 0 = 206\n",
      "Maximum duration: 334.0\n",
      "Minimum duration: 137.0\n",
      "Standard Deviation of duration: 30.703123984327853\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.8728755308490435\n",
      "Mean Squared Error: 158.98744176592916\n",
      "Root Mean Squared Error: 12.609022236713248\n",
      "Mean Absolute Error: 9.110386491584011\n",
      "Mean Absolute Percentage Error: 4.633604703694778%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8745571574593904\n",
      "Mean Squared Error: 159.85258643026796\n",
      "Root Mean Squared Error: 12.643282264913173\n",
      "Mean Absolute Error: 9.070692860002744\n",
      "Mean Absolute Percentage Error: 4.633566882219875%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.9482546051030439\n",
      "Mean Squared Error: 373.9194332442165\n",
      "Root Mean Squared Error: 19.336996489739985\n",
      "Mean Absolute Error: 14.328354036335833\n",
      "Mean Absolute Percentage Error: 7.199587164790794%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.747800775606769\n",
      "Mean Squared Error: 477.33639283390255\n",
      "Root Mean Squared Error: 21.848029495446553\n",
      "Mean Absolute Error: 16.638916985210848\n",
      "Mean Absolute Percentage Error: 8.511948024897213%\n",
      "*******************************************************************************\n",
      "Number of training samples in label 1 = 640\n",
      "Number of test samples in label 1 = 160\n",
      "Maximum duration: 471.0\n",
      "Minimum duration: 163.0\n",
      "Standard Deviation of duration: 57.18816364369029\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.8126327988754961\n",
      "Mean Squared Error: 594.4210796080188\n",
      "Root Mean Squared Error: 24.380752236303515\n",
      "Mean Absolute Error: 18.079106505379382\n",
      "Mean Absolute Percentage Error: 6.8638420841055865%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8185057714417017\n",
      "Mean Squared Error: 594.7402947108608\n",
      "Root Mean Squared Error: 24.387297814863803\n",
      "Mean Absolute Error: 18.243067506650533\n",
      "Mean Absolute Percentage Error: 6.95697268539011%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.947397647655954\n",
      "Mean Squared Error: 1044.3683191115138\n",
      "Root Mean Squared Error: 32.3166879353611\n",
      "Mean Absolute Error: 23.50769455266955\n",
      "Mean Absolute Percentage Error: 8.897499672478355%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.8145307027445581\n",
      "Mean Squared Error: 1146.651140923251\n",
      "Root Mean Squared Error: 33.86223768334354\n",
      "Mean Absolute Error: 24.642745805500915\n",
      "Mean Absolute Percentage Error: 9.440723437452787%\n",
      "*******************************************************************************\n",
      "Number of training samples in label 2 = 1028\n",
      "Number of test samples in label 2 = 258\n",
      "Maximum duration: 463.0\n",
      "Minimum duration: 142.0\n",
      "Standard Deviation of duration: 43.146051279775115\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.8391539060064381\n",
      "Mean Squared Error: 296.35144721864634\n",
      "Root Mean Squared Error: 17.214861231466443\n",
      "Mean Absolute Error: 12.284078750291998\n",
      "Mean Absolute Percentage Error: 5.346625640385947%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8401491400502574\n",
      "Mean Squared Error: 305.5254063937582\n",
      "Root Mean Squared Error: 17.479285065292522\n",
      "Mean Absolute Error: 12.50626144220048\n",
      "Mean Absolute Percentage Error: 5.449095049133061%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.9156498326951862\n",
      "Mean Squared Error: 730.5726917475021\n",
      "Root Mean Squared Error: 27.029108230711238\n",
      "Mean Absolute Error: 20.727863841907446\n",
      "Mean Absolute Percentage Error: 9.07107043302234%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.5963750363065998\n",
      "Mean Squared Error: 955.7847738875474\n",
      "Root Mean Squared Error: 30.91576901659649\n",
      "Mean Absolute Error: 24.134737325123456\n",
      "Mean Absolute Percentage Error: 10.984904660228883%\n",
      "*******************************************************************************\n",
      "Number of training samples in label 3 = 2060\n",
      "Number of test samples in label 3 = 516\n",
      "Maximum duration: 408.0\n",
      "Minimum duration: 132.0\n",
      "Standard Deviation of duration: 30.73401847768336\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.82030286118462\n",
      "Mean Squared Error: 4529.671855666941\n",
      "Root Mean Squared Error: 67.30283690652973\n",
      "Mean Absolute Error: 13.26099423712731\n",
      "Mean Absolute Percentage Error: 6.151800611006008%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8230522804297342\n",
      "Mean Squared Error: 4837.152678572382\n",
      "Root Mean Squared Error: 69.54964182921708\n",
      "Mean Absolute Error: 13.442513474483409\n",
      "Mean Absolute Percentage Error: 6.238817025595637%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.9335665249177171\n",
      "Mean Squared Error: 354.6081932017546\n",
      "Root Mean Squared Error: 18.831043338109406\n",
      "Mean Absolute Error: 14.220584224722305\n",
      "Mean Absolute Percentage Error: 6.852106749297758%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.599387071168564\n",
      "Mean Squared Error: 476.26228503494156\n",
      "Root Mean Squared Error: 21.823434308901557\n",
      "Mean Absolute Error: 17.175716741999608\n",
      "Mean Absolute Percentage Error: 8.44151275492576%\n",
      "*******************************************************************************\n",
      "Number of training samples in label 4 = 496\n",
      "Number of test samples in label 4 = 124\n",
      "Maximum duration: 457.0\n",
      "Minimum duration: 158.0\n",
      "Standard Deviation of duration: 57.27211411001512\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.8408644208440946\n",
      "Mean Squared Error: 1243.4118958553593\n",
      "Root Mean Squared Error: 35.26204610988079\n",
      "Mean Absolute Error: 21.172538228984735\n",
      "Mean Absolute Percentage Error: 8.102770019537802%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8343009511128431\n",
      "Mean Squared Error: 1182.4300930713648\n",
      "Root Mean Squared Error: 34.38648125457684\n",
      "Mean Absolute Error: 21.651636946267832\n",
      "Mean Absolute Percentage Error: 8.30486457968991%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.9513607542877623\n",
      "Mean Squared Error: 1022.2485483364458\n",
      "Root Mean Squared Error: 31.972621855838565\n",
      "Mean Absolute Error: 23.34382403819299\n",
      "Mean Absolute Percentage Error: 9.356554498520701%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.8056664787323373\n",
      "Mean Squared Error: 1244.0683812531265\n",
      "Root Mean Squared Error: 35.271353550057114\n",
      "Mean Absolute Error: 26.17824404458103\n",
      "Mean Absolute Percentage Error: 10.668658139331576%\n",
      "*******************************************************************************\n",
      "Number of training samples in label 5 = 218\n",
      "Number of test samples in label 5 = 55\n",
      "Maximum duration: 459.0\n",
      "Minimum duration: 160.0\n",
      "Standard Deviation of duration: 53.58751394338647\n",
      "\n",
      "Lasso Regression\n",
      "R^2: 0.8748995986304186\n",
      "Mean Squared Error: 1132.6818398434743\n",
      "Root Mean Squared Error: 33.655338950060724\n",
      "Mean Absolute Error: 23.621581517356624\n",
      "Mean Absolute Percentage Error: 9.632434827312789%\n",
      "*******************************************************************************\n",
      "Ridge Regression\n",
      "R^2: 0.8777194023658518\n",
      "Mean Squared Error: 1185.5645081798489\n",
      "Root Mean Squared Error: 34.432027360872155\n",
      "Mean Absolute Error: 24.26411268178517\n",
      "Mean Absolute Percentage Error: 9.827681021698114%\n",
      "*******************************************************************************\n",
      "Random Forest Regression\n",
      "R^2: 0.9325458598429711\n",
      "Mean Squared Error: 774.819333413982\n",
      "Root Mean Squared Error: 27.835576757343865\n",
      "Mean Absolute Error: 18.680305070182342\n",
      "Mean Absolute Percentage Error: 7.6213846601389506%\n",
      "*******************************************************************************\n",
      "Adaboost Regressor\n",
      "R^2: 0.8887336238630544\n",
      "Mean Squared Error: 926.6021428068749\n",
      "Root Mean Squared Error: 30.440140321734308\n",
      "Mean Absolute Error: 22.042730174136928\n",
      "Mean Absolute Percentage Error: 9.100865009984938%\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=6, n_init=\"auto\").fit(X)\n",
    "for label in set(kmeans.labels_):\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X[kmeans.labels_ == label], y[kmeans.labels_ == label], test_size=0.2)\n",
    "    except ValueError:\n",
    "        print(\"Training and Test Data are the same\")\n",
    "        X_train = X[kmeans.labels_ == label]\n",
    "        X_test = X[kmeans.labels_ == label]\n",
    "        y_train = y[kmeans.labels_ == label]\n",
    "        y_test = y[kmeans.labels_ == label]\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    try:\n",
    "        lasso_model = LassoCV(cv=10, max_iter=100000).fit(X_train, y_train)\n",
    "    except ValueError:\n",
    "        lasso_model = LassoCV(cv=2, max_iter=100000).fit(X_train, y_train)\n",
    "    lasso_model_predict = lasso_model.predict(X_test)\n",
    "    print(f\"Number of training samples in label {label} = {len(y_train)}\")\n",
    "    print(f\"Number of test samples in label {label} = {len(y_test)}\")\n",
    "    print(\n",
    "        f\"Maximum duration: {np.max(scaler.inverse_transform(y[kmeans.labels_ == label].reshape(-1,1)))}\")\n",
    "    print(\n",
    "        f\"Minimum duration: {np.min(scaler.inverse_transform(y[kmeans.labels_ == label].reshape(-1,1)))}\")\n",
    "    print(\n",
    "        f\"Standard Deviation of duration: {np.std(scaler.inverse_transform(y[kmeans.labels_ == label].reshape(-1,1)))}\")\n",
    "    print()\n",
    "    print(\"Lasso Regression\")\n",
    "    print(f\"R^2: {lasso_model.score(X_train, y_train)}\")\n",
    "    report_score(scaler.inverse_transform(y_test.reshape(-1, 1)),\n",
    "                 scaler.inverse_transform(lasso_model_predict.reshape(-1, 1)))\n",
    "    print(\"*\"*79)\n",
    "\n",
    "    try:\n",
    "        ridge_model = RidgeCV(cv=10).fit(X_train, y_train)\n",
    "    except ValueError:\n",
    "        ridge_model = RidgeCV(cv=2).fit(X_train, y_train)\n",
    "    ridge_model_predict = ridge_model.predict(X_test)\n",
    "    print(\"Ridge Regression\")\n",
    "    print(f\"R^2: {ridge_model.score(X_train, y_train)}\")\n",
    "    report_score(scaler.inverse_transform(y_test.reshape(-1, 1)),\n",
    "                 scaler.inverse_transform(ridge_model_predict.reshape(-1, 1)))\n",
    "    print(\"*\"*79)\n",
    "\n",
    "    rf_regr = RandomForestRegressor(min_samples_leaf=2).fit(X_train, y_train)\n",
    "    rf_regr_predict = rf_regr.predict(X_test)\n",
    "    print(\"Random Forest Regression\")\n",
    "    print(f\"R^2: {rf_regr.score(X_train, y_train)}\")\n",
    "    report_score(scaler.inverse_transform(y_test.reshape(-1, 1)),\n",
    "                 scaler.inverse_transform(rf_regr_predict.reshape(-1, 1)))\n",
    "    print(\"*\"*79)\n",
    "\n",
    "    adaboost = AdaBoostRegressor(\n",
    "        learning_rate=0.5, loss=\"square\", n_estimators=50).fit(X_train, y_train)\n",
    "    adaboost_predict = adaboost.predict(X_test)\n",
    "    print(\"Adaboost Regressor\")\n",
    "    print(f\"R^2: {adaboost.score(X_train, y_train)}\")\n",
    "    report_score(scaler.inverse_transform(y_test.reshape(-1, 1)), scaler.inverse_transform(adaboost_predict.reshape(-1, 1)))\n",
    "    print(\"*\"*79)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
